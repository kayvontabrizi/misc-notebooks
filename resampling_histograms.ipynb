{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264423c6",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## imports & configuration\n",
    "\n",
    "# standard imports\n",
    "\n",
    "# custom imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "# inline plots\n",
    "%config InlineBackend.figure_formats = ['svg']\n",
    "# %matplotlib notebook\n",
    "\n",
    "# jupyter theme\n",
    "try:\n",
    "    import jupyterthemes as jt\n",
    "    jt.jtplot.style()\n",
    "except ImportError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c0492e",
   "metadata": {},
   "source": [
    "-------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54304c60",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# prep and seed random number generator\n",
    "rng = np.random.default_rng(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38729163",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## sample from a n-simplex\n",
    "\n",
    "# sample n points from a d-dimensional simplex\n",
    "def simplex(n, d):\n",
    "    exps = -np.log(rng.random((n, d))) # draw from exp(-x)\n",
    "    return exps/exps.sum(axis=-1)[:, None] # normalize sum to 1\n",
    "\n",
    "# rotate simplex points and plot (should be a uniform distribution)\n",
    "plt.figure(figsize=(6, 3))\n",
    "r_mat = Rotation.from_euler('z', np.pi/4).as_matrix()[:2, :2]\n",
    "plt.hist(r_mat.dot(simplex(100000, 2).T)[0]*np.sqrt(0.5)+0.5, bins=100, density=True)\n",
    "plt.xlabel(\"parameter along $(x + y = 1)$\")\n",
    "plt.ylabel(\"density\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca6ffda",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## compute boostrap-based uncertainty in discrete distribution\n",
    "\n",
    "# configuration\n",
    "n_samples = 1000 # number of samples\n",
    "d = 5 # number of states\n",
    "\n",
    "# generate samples from random distribution with d states\n",
    "states = np.arange(d)\n",
    "ps = simplex(1, d)[0]\n",
    "samples = rng.choice(states, n_samples, p=ps)\n",
    "_, counts = np.unique(samples, return_counts=True)\n",
    "ps = counts/n_samples\n",
    "\n",
    "# bootstrap to compute probability uncertainties\n",
    "errors = np.array([\n",
    "    scipy.stats.bootstrap(samples[None, :], lambda _samples: (_samples == state).sum()/len(_samples), vectorized=False).standard_error\n",
    "    for state in states\n",
    "])\n",
    "\n",
    "# create histogram\n",
    "plt.bar(states, ps, yerr=errors)\n",
    "plt.xlabel(\"state\")\n",
    "plt.ylabel(\"density\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c18aba",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## method to compute bootstrap-based uncertainty estimates\n",
    "def compute_uncertainty_in_distribution(n_samples, d):\n",
    "    # generate samples from random distribution with d states\n",
    "    states = np.arange(d)\n",
    "    ps = simplex(1, d)[0]\n",
    "    samples = rng.choice(states, n_samples, p=ps)\n",
    "    _, counts = np.unique(samples, return_counts=True)\n",
    "    ps = counts/n_samples\n",
    "\n",
    "    # bootstrap to compute probability uncertainties\n",
    "    errors = np.array([\n",
    "        scipy.stats.bootstrap(samples[None, :], lambda _samples: (_samples == state).sum()/len(_samples), vectorized=False).standard_error\n",
    "        for state in states\n",
    "    ])\n",
    "\n",
    "    # return sampling distribution and associated uncertainties\n",
    "    return ps, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842ce399",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# compute errors for a variety of sample sizes\n",
    "ns = np.arange(200, 1100, 100)\n",
    "pses, errorses = zip(*[compute_uncertainty_in_distribution(n, 6) for n in ns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d84d68",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## examine relationship between errors and sample size\n",
    "\n",
    "# initialize figure\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 3))\n",
    "\n",
    "# plot the constant (== error**2 / probability) averaged across states\n",
    "scalings = (np.stack(errorses)**2/np.stack(pses))\n",
    "axes[0].errorbar(ns, scalings.mean(axis=-1), yerr=scalings.std(axis=-1)/np.sqrt(scalings.shape[1]))\n",
    "axes[0].scatter(ns, scalings.mean(axis=-1))\n",
    "axes[0].set_xlabel(\"# of samples\")\n",
    "axes[0].set_ylabel(\"$\\sigma(p_i)^2$ / $p_i$\")\n",
    "\n",
    "# recognize 1/n shape, plot full error relationship\n",
    "axes[1].axhline(1-(1/scalings.shape[1]), color='k', ls='--', lw=0.5)\n",
    "axes[1].plot(ns, scalings.mean(axis=-1)*ns, \"o-\")\n",
    "axes[1].set_xlabel(\"# of samples\")\n",
    "axes[1].set_ylabel(\"$n * \\sigma(p_i)^2$ / $p_i$\")\n",
    "\n",
    "# display figure\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f77721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deduce relationship between probability, # of states, and # of samples\n",
    "std_err = lambda p, d, n: np.sqrt(p*(1-(1/d))/n) # !avg(ps) == 1-(1/d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b70fdc2",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# compare empirical and analytic uncertainties\n",
    "plt.plot(*[(std_err(0, d, n_samples), std_err(1, d, n_samples))]*2, c='k', ls='--', lw=1)\n",
    "plt.scatter(errors, [std_err(p, d, n_samples) for p in ps])\n",
    "plt.xlabel(\"empirical uncertainty\")\n",
    "plt.ylabel(\"analytic uncertainty\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1635d007",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feeef354",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## bootstrap the -ln(p) uncertainty\n",
    "\n",
    "# configuration\n",
    "n_samples = 10000 # number of samples\n",
    "d = 10 # number of states\n",
    "\n",
    "# generate samples from random distribution with d states\n",
    "states = np.arange(d)\n",
    "ps = simplex(1, d)[0]\n",
    "samples = rng.choice(states, n_samples, p=ps)\n",
    "_, counts = np.unique(samples, return_counts=True)\n",
    "ps = counts/n_samples\n",
    "\n",
    "# bootstrap to compute probability uncertainties\n",
    "boots = np.array([\n",
    "    scipy.stats.bootstrap(samples[None, :], lambda _samples: -np.log((_samples == state).sum()/len(_samples)), vectorized=False)\n",
    "    for state in states\n",
    "])\n",
    "errors = np.array([b.standard_error for b in boots])\n",
    "\n",
    "# plot -logPs with errors\n",
    "plt.bar(states, -np.log(ps), yerr=errors)\n",
    "plt.xlabel(\"state\")\n",
    "plt.ylabel(\"-logP\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b65feb",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# compare empirical and analytic -logp uncertainties\n",
    "plt.plot(*[(0, std_err(ps.min(), d, n_samples)/ps.min())]*2, c='k', ls='--', lw=1)\n",
    "plt.scatter(errors, np.array([std_err(p, d, n_samples) for p in ps])/ps)\n",
    "plt.xlabel(\"empirical uncertainty\")\n",
    "plt.ylabel(\"analytic uncertainty\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf03b39",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# slowly compute dGs from i -> i+1 (takes like 2-3 minutes)\n",
    "dG_errs = np.array([\n",
    "    scipy.stats.bootstrap(\n",
    "        samples[None, :],\n",
    "        lambda _samples: np.diff(-np.log(np.unique(_samples, return_counts=True)[1]/len(_samples)))[i],\n",
    "        vectorized=False\n",
    "    ).standard_error\n",
    "    for i in range(len(states)-1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af912a79",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## compare empirical and analytic dG errors\n",
    "\n",
    "# analytic dG error computation\n",
    "_err = (np.array([std_err(p, d, n_samples) for p in ps])/ps)\n",
    "_dG_errs = np.sqrt((_err**2)[:-1]+(_err**2)[1:])\n",
    "_dG_errs *= np.sqrt(d/(d-1)) # not sure why this second factor is necessary\n",
    "\n",
    "# compare empirical and analytic uncertainties\n",
    "plt.plot(*[(0, max(dG_errs.max(), _dG_errs.max()))]*2, c='k', ls='--', lw=1)\n",
    "plt.scatter(dG_errs, _dG_errs)\n",
    "plt.xlabel(\"empirical uncertainty\")\n",
    "plt.ylabel(\"analytic uncertainty\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471bbf3f",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13e802c",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# method to compute i->i+1 dG error from sampling distribution (and # of samples)\n",
    "def dG_err(ps, n_samples):\n",
    "    d = len(ps)\n",
    "    p_err = np.array([np.sqrt(p*(1-(1/d))/n_samples) for p in ps])\n",
    "    logp_err = p_err/ps\n",
    "    correction = np.sqrt(d/(d-1))\n",
    "    dg_err = np.sqrt((logp_err**2)[:-1]+(logp_err**2)[1:])*correction\n",
    "    return p_err, dg_err # returns standard error in p and -log(p_{i+1}/p_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a8bf9f",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
